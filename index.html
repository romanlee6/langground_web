<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/new_langGround_framework.pdf" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/new_langGround_framework.pdf">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Language Grounded Multi-agent Reinforcement Learning with Human-interpretable Communication</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Language Grounded Multi-agent Reinforcement Learning with Human-interpretable Communication</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://www.huao-li.com/" target="_blank">Huao Li</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/hossein-nourkhiz-mahjoub-46933446/" target="_blank">Hossein Nourkhiz Mahjoub</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://www.linkedin.com/in/behdadchalaki/" target="_blank">Behdad Chalaki</a><sup>2</sup>,</span>
                                      <span class="author-block">
                    <a href="https://www.linkedin.com/in/vaishnav-tadiparthi/" target="_blank">Vaishnav Tadiparthi</a><sup>2</sup>,</span>
                                    <span class="author-block">
                    <a href="https://www.linkedin.com/in/kwonjoon-lee-062309a3/" target="_blank">Kwonjoon Lee</a><sup>2</sup>,</span>
                                    <span class="author-block">
                    <a href="https://www.linkedin.com/in/ehsan-moradi-pari-8a73ba53/" target="_blank">Ehsan Moradi-Pari</a><sup>2</sup>,</span>
                                    <span class="author-block">
                    <a href="https://www.sci.pitt.edu/people/michael-lewis" target="_blank">Michael Lewis</a><sup>1</sup>,</span>
                                    <span class="author-block">
                    <a href="https://www.cs.cmu.edu/~sycara/" target="_blank">Katia Sycara</a><sup>3</sup></span>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"> NeurIPS 2024 Paper</span>
                    <span class="eql-cntrb"><small><br><sup>1</sup>University of Pittsburgh,<sup>2</sup>Honda Research Institute USA,<sup>3</sup>Carnegie Mellon University</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2409.17348.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>


                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/romanlee6/langground" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2409.17348" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
<img src="static/images/new_langGround_framework.png" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        <b>LangGround</b> is a novel computational pipeline for MARL agents to learn human-interpretable communication in ad-hoc human-agent teamwork.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Multi-Agent Reinforcement Learning (MARL) methods have shown promise in enabling agents to learn a shared communication protocol from scratch and accomplish challenging team tasks. However, the learned language is usually not interpretable to humans or other agents not co-trained together, limiting its applicability in ad-hoc teamwork scenarios. In this work, we propose a novel computational pipeline that aligns the communication space between MARL agents with an embedding space of human natural language by grounding agent communications on synthetic data generated by embodied Large Language Models (LLMs) in interactive teamwork scenarios. Our results demonstrate that introducing language grounding not only maintains task performance but also accelerates the emergence of communication. Furthermore, the learned communication protocols exhibit zero-shot generalization capabilities in ad-hoc teamwork scenarios with unseen teammates and novel task states. This work presents a significant step toward enabling effective communication and collaboration between artificial agents and humans in real-world teamwork settings.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Demo</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">

          <div class="publication-video">
            <!-- Youtube embed code here -->
                  <video poster="" id="demo" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/demo_example.mp4" type="video/mp4">
      </video>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>




  <section class="section is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3">Task Performance</h2>
          <div class="level-set has-text-justified">
            <p>
             We first consider if LangGround allows MARL agents to complete collaborative tasks successfully and converge to a shared communication protocol quickly. LangGround enables multi-agent teams to achieve on-par performance in comparison
with SOTA multi-agent communication methods. Introducing language grounds as an auxiliary
learning objective does not compromise the task utility of learned communication protocols while
providing interpretability.
            </p>
          </div>
          <img src="static/images/performance.png" alt="Baselines vs. RGB" class="center-image">
        </div>
      </div>
    </div>
  </div>
</section>

  <section class="section is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3">Langauge Alignment</h2>
          <div class="level-set has-text-justified">
            <p>
              Then we analyze the properties of aligned communication space to show how close the learned language is to the target human natural language. The reference message accurately refers to the agent observation, indicating the learned communication space is semantically meaningful and highly aligned with the target embedding space.
            </p>
          </div>
          <img src="static/images/alignment.png" alt="Baselines vs. RGB" class="center-image">
        </div>
      </div>
    </div>
  </div>
</section>



  <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">

      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3">Ad-hoc Teamwork</h2>
          <div class="level-set has-text-justified">
            <p>
            Finally, we evaluate the performance of LangGround agents in ad-hoc teams with 2 unseen LLM agents as teammates. LangGround outperforms baseline methods in two out of three evaluation scenarios.
            </p>
            <img src="static/images/adhoc.png" alt="Visualize most dist patch" class="center-image blend-img-background">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">

          <div class="publication-video">
            <!-- Youtube embed code here -->
                  <video poster="" id="tree" controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/Demo video.mp4" type="video/mp4">
      </video>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>







<!--&lt;!&ndash; Paper poster &ndash;&gt;-->
<!--<section class="hero is-small is-light">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <h2 class="title">Poster</h2>-->

<!--      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">-->
<!--          </iframe>-->
<!--        -->
<!--      </div>-->
<!--    </div>-->
<!--  </section>-->
<!--&lt;!&ndash;End paper poster &ndash;&gt;-->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{li2024languagegroundedmultiagentcommunication,
      title={Language Grounded Multi-agent Communication for Ad-hoc Teamwork},
      author={Huao Li and Hossein Nourkhiz Mahjoub and Behdad Chalaki and Vaishnav Tadiparthi and Kwonjoon Lee and Ehsan Moradi-Pari and Charles Michael Lewis and Katia P Sycara},
      year={2024},
      eprint={2409.17348},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2409.17348},
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This work was done while the first author interning at Honda Research Institute USA.
            <br> This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            </a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
